include "memory.pil";
include "calldata.pil";
include "precomputed.pil";
include "constants_gen.pil";
include "gt.pil";

/** This trace handles CALLDATACOPY and RETURNDATACOPY
 * The data_copy gadget handles CALLDATACOPY and RETURNDATACOPY (both enqueued and nested)
 *
 * Opcode operands (relevant in EXECUTION when interacting with this gadget):
 * - register[0]: copy_size
 * - register[1]: copy_offset
 * - rop[2]: dst_addr
 *
 * Memory I/O, this subtrace can potentially read and write across two different memory space ids (indicated by the context_ids)
 * All reads are performed in the src context (using the src_context_id) and writes are performed in the current executing
 * context (using dst_context_id).
 * - M[src_addr]: aka value[0] (the first value read from the src context)
 *     - the memory tag is ignored for these reads
 * - M[src_addr + data_index_upper_bound - 1]: aka value[data_index_upper_bound - 1] (the last value read from the src context)
 *     - data_index_upper_bound is derived from the copy_size, see pil relations for an explanation
 *     - the memory tag is ignored for these reads
 * - M[dst_addr]: aka output[0] (the first value written to the dst context)
 *     - guaranteed by this gadget to be FF
 * - M[dst_addr + copy_size - 1]: aka output[copy_size - 1] (the last value written to the dst context)
 *     - guaranteed by this gadget to be FF
 *
 * ERROR HANDLING:
 * There is one type of potential errors that is checked: memory out of range accesses
 * They are checked simultaneously and are part of the same temporality group.
 * - src_out_of_range_err: if the read address is out of range
 * - dst_out_of_range_err: if the write address is out of range
 * - err: if either of the above errors is set
 * If there are no errors, we read and write the calldata/returndata from the parent/child context to the current context
 * COMPUTING AMOUNT OF DATA TO READ
 * We need to ensure that we do not read outside the bounds designated by the parent/child context for their respective data.
 * this data_index_upper_bound is computed via min(data_size, copy_size + copy_offset).
 *
 * READING / WRITING DATA
 * At each row, the i-th data is simultaneously read from the parent/child and written into the current context
 * For top level calldatacopy, the data is retrieved from the calldata column instead of memory.
 * The number of reads that are performed is (data_index_upper_bound - copy_offset), while the number of writes is copy_size
 * If the data_index_upper_bound < copy_offset, the number of reads is constrained to be 0.
 * If num_reads < copy_size, the remaining (copy_size - num_reads) rows are designated as padding rows.
 * padding rows are constrained to have the value = 0.
 *
 * It is memory aware and so is expected to call the memory subtrace directly
 *
 * Note that there are two ways that this subtrace is invoked from the execution trace: CD_COPY or RD_COPY
 * This requires two permutations because they operate on different execution trace cols (parent vs child).
 * IMPORTANT: They must be used as permutations as to prevent any malicious insertions which would corrupt
 * the memory trace.
 *
 * Usage: CD COPY
 * execution.sel_calldata_copy {
 *     precomputed.clk,
 *     parent_id, context_id,
 *     reg[0], reg[1], rop[2],
 *     parent_calldata_addr, parent_calldata_size,
 *     sel_opcode_error
 * }
 * is
 * sel_cd_copy_start {
 *     clk,
 *     src_context_id, dst_context_id,
 *     copy_size, offset, dst_addr,
 *     src_addr, src_data_size,
 *     err
 * }
 *
 * Usage: RD COPY
 * execution.sel_returndata_copy {
 *     precomputed.clk,
 *     last_child_id, context_id,
 *     reg[0], reg[1], rop[2],
 *     last_child_returndata_addr, last_child_returndata_size,
 *     sel_opcode_error
 * }
 * is
 * sel_rd_copy_start {
 *     clk,
 *     src_context_id, dst_context_id,
 *     copy_size, offset, dst_addr,
 *     src_addr, src_data_size,
 *     err
 * };
 *
 * Inputs:
 * @column clk The clock which is propagated down to the memory subtrace.
 * @column src_context_id The context that is read from.
 * @column dst_context_id The context that is written to.
 * @column copy_size The number of writes.
 * @column offset The offset within the data to start copying.
 * @column dst_addr The address of the start of the data in the current context.
 * @column src_addr The address of the start of the data in the parent/child context.
 * @column src_data_size The size of the data in the parent/child context.
 *
 * Output:
 * @column err The error flag.
 *
 * Multi-rows computation:
 * 1) Happy path: number of rows = copy_size
 * 2) Error case or copy_size = 0 or 1: single row
 *
 * Interactions with the following subtraces:
 * - memory (reads and writes)
 * - calldata (reads for top level cd copy)
 * - gt
 *
 * Example: Reading from calldata column
 * Calldata Trace
 * +-----+-------+-------+------------+
 * | sel | value | index | context_id |
 * +-----+-------+-------+------------+
 * |   1 |   100 |     1 |          1 |
 * |   1 |   200 |     2 |          1 |
 * |   1 |   300 |     3 |          1 |
 * +-----+-------+-------+------------+
 * Execution Trace                         (dst_addr)      (cd_size)   (cd_offset)
 * +-----+-----+------------+-----------+---------------+------------+------------+
 * | clk | sel | context_id | parent_id | resolved_op_2 | register_0 | register_1 |
 * +-----+-----+------------+-----------+---------------+------------+------------+
 * |   1 |   1 |          1 |         0 |       5       |     3      |     0      |
 * +-----+-----+------------+-----------+---------------+------------+------------+
 * DataCopy Trace
 * +-------------+------------+------------+-----------+------------------+----------+-------+------------+
 * | sel_cd_copy | src_ctx_id | dst_ctx_id | copy_size | cd_copy_col_read | cd_index | value |  dst_addr  |
 * +-------------+------------+------------+-----------+------------------+----------+-------+------------+
 * |           1 |          0 |          1 |         3 |                1 |        1 |   100 |          5 |
 * |           1 |          0 |          1 |         2 |                1 |        2 |   200 |          6 |
 * |           1 |          0 |          1 |         1 |                1 |        3 |   300 |          7 |
 * +-------------+------------+------------+-----------+------------------+----------+-------+------------+
 */

namespace data_copy;
    pol commit sel;
    sel * (1 - sel) = 0;

    #[skippable_if]
    sel = 0;

    // Selector to tell apart calldata_copy from returndata_copy.
    pol commit sel_cd_copy; // @boolean For calldata_copy, sel_cd_copy = 1 and returndata_copy, sel_cd_copy = 0.
    sel_cd_copy * (1 - sel_cd_copy) = 0;

    ///////////////////////////////
    // Trace Shape
    ///////////////////////////////
    // Trace is contiguous.
    #[TRACE_CONTINUITY]
    (1 - precomputed.first_row) * (1 - sel) * sel' = 0;

    pol commit sel_start; // @boolean
    sel_start * (1 - sel_start) = 0;
    // End controls most of the row propagation, so if we error we also set end to turn off row propagation
    pol commit sel_end; // @boolean
    sel_end * (1 - sel_end) = 0;

    // sel_end = 1 OR sel_start ==> sel = 1
    (sel_start + sel_end) * (1 - sel) = 0;

    // This prevents a computation to be stopped prematurely, i.e., truncating last rows before
    // we reach a row where sel_end == 1.
    #[COMPUTATION_FINISH_AT_END]
    sel * (1 - sel') * (1 - sel_end) = 0;

    // Latch condition is boolean because sel_end cannot be activated at first row
    // because sel is shifted and sel_end implies sel == 1.
    pol LATCH_CONDITION = sel_end + precomputed.first_row;

    // By enforcing the start of a new computation after a latch, we ensure that no superfluous rows are added.
    // In combination with the permutations from the execution trace, it follows that each active row is
    // part of a genuine computation. We particularly need to be careful that no malicious memory write is
    // performed.
    #[START_AFTER_LATCH]
    sel' * (sel_start' - LATCH_CONDITION) = 0;

    ////////////////////////////////////////////////
    // Dispatch Permutation Selectors
    ////////////////////////////////////////////////
    // These permutations are defined in execution.pil. See #[DISPATCH_TO_CD_COPY] and #[DISPATCH_TO_RD_COPY].

    pol commit sel_cd_copy_start; // @boolean follows from the definition
    sel_cd_copy_start = sel_start * sel_cd_copy;

    pol commit sel_rd_copy_start; // @boolean follows from the definition
    sel_rd_copy_start = sel_start * (1 - sel_cd_copy);

    // It follows from the above equations that sel_cd_copy_start and sel_rd_copy_start are mutually exclusive
    // and that sel_cd_copy_start + sel_rd_copy_start = sel_start.
    // sel_cd_copy also the correct value on the start row:
    // sel_cd_copy_start == 1 ==> sel_cd_copy == 1
    // sel_rd_copy_start == 1 ==> sel_cd_copy == 0

    ///////////////////////////////
    // Inputs from execution trace
    ///////////////////////////////
    pol commit clk;
    pol commit src_context_id; // The context that is read from
    pol commit dst_context_id; // The context that is written to

    pol commit copy_size; // This is also the number of writes
    pol commit offset; // This is the offset within the data to start copying
    pol commit src_addr; // This is the address of the start of the data in parent/child, should be 0 for top level
    pol commit src_data_size; // This is the size of the data in parent/child
    pol commit dst_addr;

    //////////////////////////////////////
    // Computing the src index upper bound
    //////////////////////////////////////
    // Computing the read count, i.e. the number of elements that will be read from the src data.
    // We compute the data index upper bound using min(offset + copy_size, src_data_size)
    // This ensures that we cannot read pass the designated data address assigned by the parent/child
    // The min operation is essentially checking the comparison of the following
    // 1) (offset + copy_size) > src_data_size or
    // 2) (offset + copy_size) <= src_data_size
    // if (1) then data_index_upper_bound = src_data_size, otherwise data_index_upper_bound = (offset + copy_size)
    pol commit offset_plus_size;
    offset_plus_size = sel_start * (offset + copy_size);
    pol commit offset_plus_size_is_gt; // @boolean follows from the lookup into gt.

    #[OFFSET_PLUS_SIZE_IS_GT_DATA_SIZE]
    sel_start { offset_plus_size, src_data_size, offset_plus_size_is_gt }
    in
    gt.sel_others { gt.input_a, gt.input_b, gt.res };

    // Set data_index_upper_bound based on the conditions (1) or (2) from above
    pol commit data_index_upper_bound;
    data_index_upper_bound = sel_start * ((src_data_size - offset_plus_size) * offset_plus_size_is_gt + offset_plus_size);

    //////////////////////////////
    // Error Handling
    //////////////////////////////
    // Errors on whether the read or write addresses are out of range in memory. (provided that sel_start == 1).
    pol commit src_out_of_range_err; // @boolean follows from the lookup into gt.
    pol commit dst_out_of_range_err; // @boolean follows from the lookup into gt.

    // AVM_MEMORY_SIZE == AVM_HIGHEST_MEM_ADDRESS + 1.
    pol commit mem_size; // todo: While we do not support constants
    sel_start * (mem_size - constants.AVM_MEMORY_SIZE) = 0;

    // To check that the read and write addresses are within range, we compare the upper bound
    // of the read/write addresses to the memory size. Working with upper bounds is easier than
    // working with the highest read/write address as we avoid an underflow when src_addr/dst_addr
    // and copy_size/data_index_upper_bound are both zero.
    // Example: src_addr = AVM_HIGHEST_MEM_ADDRESS, data_index_upper_bound = 1 is perfectly valid
    // and read_addr_upper_bound = AVM_HIGHEST_MEM_ADDRESS + 1 <= AVM_MEMORY_SIZE.
    // An out-of-range error is raised when read_addr_upper_bound/write_addr_upper_bound > AVM_MEMORY_SIZE.

    // Note that for a top-level call, src_addr == 0 (enforced outside of this subtrace) and src_out_of_range_err == 0.
    pol commit read_addr_upper_bound;
    read_addr_upper_bound = sel_start * (src_addr + data_index_upper_bound);
    #[CHECK_SRC_ADDR_IN_RANGE]
    sel_start { read_addr_upper_bound, mem_size, src_out_of_range_err }
    in
    gt.sel_others { gt.input_a, gt.input_b, gt.res };

    pol commit write_addr_upper_bound;
    write_addr_upper_bound = sel_start * (dst_addr + copy_size);
    #[CHECK_DST_ADDR_IN_RANGE]
    sel_start { write_addr_upper_bound, mem_size, dst_out_of_range_err }
    in
    gt.sel_others { gt.input_a, gt.input_b, gt.res };

    // Consolidate the errors
    // Underconstrained for non-starting rows (sel_start = 0).
    pol commit err; // @boolean follows from the definition
    err = 1 - (1 - dst_out_of_range_err) * (1 - src_out_of_range_err);

    //////////////////////////////
    // Control flow management
    //////////////////////////////
    pol commit sel_start_no_err; // @boolean follows from the definition
    sel_start_no_err = sel_start * (1 - err);

    pol commit sel_write_count_is_zero; // @boolean
    sel_write_count_is_zero * (1 - sel_write_count_is_zero) = 0;
    pol commit write_count_zero_inv;
    // sel_write_count_is_zero = 1 IFF copy_size = 0 (conditioned by sel_start = 1 and there are no errors)
    #[ZERO_SIZED_WRITE]
    sel_start_no_err * (copy_size * (sel_write_count_is_zero * (1 - write_count_zero_inv) + write_count_zero_inv) - 1 + sel_write_count_is_zero) = 0;
    #[END_IF_WRITE_IS_ZERO]
    sel_start_no_err * sel_write_count_is_zero * (sel_end - 1) = 0;

    pol SEL_PERFORM_COPY = sel_start_no_err * (1 - sel_write_count_is_zero) + sel * (1 - sel_start);

    pol WRITE_COUNT_MINUS_ONE = copy_size - 1;
    pol commit write_count_minus_one_inv;
    // sel_end = 1 IFF copy_size - 1 = 0;
    #[END_WRITE_CONDITION]
    SEL_PERFORM_COPY * (WRITE_COUNT_MINUS_ONE * (sel_end * (1 - write_count_minus_one_inv) + write_count_minus_one_inv) - 1 + sel_end) = 0;

    #[END_ON_ERR] // sel_end = 1 if error
    sel_start * err * (sel_end - 1) = 0;

    pol commit reads_left; // Number of reads of the src data, if reads_left = 0 but copy_size != 0 then it is a padding row
    // src data elements are read from indices [offset, data_index_upper_bound), therefore reads_left = data_index_upper_bound - offset
    // We need to be careful that data_index_upper_bound - offset does not underflow (i.e. when offset > data_index_upper_bound, reads_left = 0)
    // We test that condition here
    pol commit data_index_upper_bound_gt_offset; // @boolean follows from the lookup into gt.
    #[DATA_INDEX_UPPER_BOUND_GT_OFFSET]
    sel_start_no_err { data_index_upper_bound, offset, data_index_upper_bound_gt_offset }
    in
    gt.sel_others { gt.input_a, gt.input_b, gt.res };

    // If data_index_upper_bound_gt_offset = 0 (i.e. when offset >= data_index_upper_bound), reads_left = 0
    // otherwise, reads_left = data_index_upper_bound - offset
    #[INIT_READS_LEFT]
    sel_start_no_err * (1 - sel_write_count_is_zero) * (reads_left - (data_index_upper_bound - offset) * data_index_upper_bound_gt_offset) = 0;

    //////////////////////////////
    // Execute Data Copy
    //////////////////////////////
    // Most of these relations are either gated explicitly by err, end, or LATCH_CONDITION.
    // ===== Writing to dst_context_id =====
    pol commit sel_mem_write; // @boolean follows from the definition (see SEL_PERFORM_COPY)
    sel_mem_write = SEL_PERFORM_COPY; // We write if there is no error and copy_size != 0

    // Data copy size decrements for each row until we end
    #[DECR_COPY_SIZE]
    sel * (1 - sel_end) * (copy_size' - copy_size + 1) = 0;

    // Write address decrements for each row until we end
    #[INCR_WRITE_ADDR]
    sel * (1 - sel_end) * (dst_addr' - dst_addr - 1) = 0;

    // Propagate the context ids, clk, and sel_cd_copy
    #[SRC_CONTEXT_ID_PROPAGATION]
    (1 - LATCH_CONDITION) * (src_context_id' - src_context_id) = 0;
    #[DST_CONTEXT_ID_PROPAGATION]
    (1 - LATCH_CONDITION) * (dst_context_id' - dst_context_id) = 0;
    #[CLK_PROPAGATION]
    (1 - LATCH_CONDITION) * (clk' - clk) = 0;
    #[SEL_CD_COPY_PROPAGATION]
    (1 - LATCH_CONDITION) * (sel_cd_copy' - sel_cd_copy) = 0;

    #[MEM_WRITE]
    sel_mem_write { clk, dst_context_id, dst_addr, value, /*mem_tag=*/precomputed.zero/*(FF)*/, /*rw=*/sel_mem_write/*(write)*/ }
    is
    memory.sel_data_copy_write { memory.clk, memory.space_id, memory.address, memory.value, memory.tag, memory.rw };

    // ===== Reading for nested call =====
    pol commit read_addr;  // The addr to start reading the data from: src_addr + offset;
    #[INIT_READ_ADDR] // Only occurs at the start if we have not errored
    sel_start_no_err * (1 - sel_write_count_is_zero) * (read_addr - src_addr - offset) = 0;
    // Subsequent read addrs are incremented by 1 unless this is a padding row
    #[INCR_READ_ADDR]
    sel * (1 - padding) * (1 - sel_end) * (read_addr' - read_addr - 1) = 0;

    // Read count decrements
    #[DECR_READ_COUNT]
    sel * (1 - padding) * (1 - sel_end) * (reads_left' - reads_left + 1) = 0;
    pol commit padding; // @boolean If we write, padding = 1 iff reads_left = 0
    padding * (1 - padding) = 0;
    pol commit reads_left_inv;
    #[PADDING_CONDITION]
    SEL_PERFORM_COPY * (reads_left * (padding * (1 - reads_left_inv) + reads_left_inv) - 1 + padding) = 0;

    // Once we enter into padding region, we do not get out of it until the end.
    #[PADDING_PROPAGATION]
    (1 - sel_end) * padding * (1 - padding') = 0;

    // Top level condition:
    // is_top_level == 1 if this is an enqueued call, i.e., iff parent_id == 0
    // Constrained only for sel_cd_copy = 1 but on all rows.
    pol commit is_top_level; // @boolean
    is_top_level * (1 - is_top_level) = 0;
    pol commit parent_id_inv; // For zero-check of is_top_level
    #[TOP_LEVEL_COND]
    sel_cd_copy * (src_context_id * (is_top_level * (1 - parent_id_inv) + parent_id_inv) - 1 + is_top_level) = 0;

    // Read from memory if we are not the top level call and not a padding row
    // If the current row is a memory op read, i.e., no error occured, copy_size != 0,
    // it is not a padding row and not a CD_COPY in a top-level call.
    pol commit sel_mem_read; // @boolean follows from the definition
    sel_mem_read = SEL_PERFORM_COPY * (1 - is_top_level * sel_cd_copy) * (1 - padding);

    // === Value Padding ===
    pol commit value;
    #[PAD_VALUE]
    padding * value = 0;

    pol commit tag; // We keep the memory tag unconstrained as each value is implicitly upcasted to FF when written.
    // We need to pass the tag as the memory multipermutation mandates that the tuple has 6 columns.
    #[MEM_READ]
    sel_mem_read { clk, src_context_id, read_addr, value, tag, /*rw=*/precomputed.zero/*(read)*/ }
    is
    memory.sel_data_copy_read { memory.clk, memory.space_id, memory.address, memory.value, memory.tag, memory.rw };

    // ===== Reading cd column for top level cd copy =====
    // Reading from column
    pol commit cd_copy_col_read; // @boolean follows from the definition
    #[CD_COPY_COLUMN]
    cd_copy_col_read = SEL_PERFORM_COPY * (1 - padding) * is_top_level * sel_cd_copy;

    // The calldata trace starts at index = 1 (TODO: We need this temporarily while we dont allow for aliases in the lookup tuple):
    pol commit read_addr_plus_one;
    read_addr_plus_one = cd_copy_col_read * (read_addr + 1);

    #[COL_READ]
    cd_copy_col_read { read_addr_plus_one, dst_context_id, value }
    in
    calldata.sel { calldata.index, calldata.context_id, calldata.value };
